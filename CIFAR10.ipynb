{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch.optim\n",
    "import torch.linalg as linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "torch.manual_seed(random_seed)\n",
    "n_epochs = 3\n",
    "batch_size_train = 40\n",
    "batch_size_test = 1\n",
    "num_classes = 10\n",
    "\n",
    "results_folder = './cifar10_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), transforms.Lambda(lambda x : torch.flatten(x))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data/', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train(net, trainloader, testloader, name=\"\", n_epochs=4, lr=0.0001):\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    test_losses = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    def train(epoch):\n",
    "        net.train()\n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            for i in range(batch_size_train):\n",
    "                d=data[i,:].float()\n",
    "                t=nn.functional.one_hot(target[i,:],num_classes=num_classes).float()\n",
    "                #optim.zero_grad()\n",
    "                o = net(d)\n",
    "                loss += loss_fn(o, t)\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    net.update_backwards()\n",
    "\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader), loss.item()))\n",
    "                train_losses.append(loss.item())\n",
    "                train_counter.append(\n",
    "                    (batch_idx*64) + ((epoch-1)*len(trainloader.dataset)))\n",
    "    \n",
    "\n",
    "    def test():\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target_idx in testloader:\n",
    "                data=torch.squeeze(data).float()\n",
    "                target_idx = torch.squeeze(target_idx)\n",
    "                target=nn.functional.one_hot(torch.squeeze(target_idx),num_classes=num_classes.float())\n",
    "                output = net(data)\n",
    "                test_loss += loss_fn(output, target).item()\n",
    "                pred_idx = torch.argmax(output.data)\n",
    "                correct += pred_idx.eq(target_idx.data).sum()\n",
    "            test_loss /= len(testloader.dataset)\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracy.append(100. * correct / len(testloader.dataset))\n",
    "            print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                    test_loss, correct, len(testloader.dataset),\n",
    "                    100. * correct / len(testloader.dataset)))\n",
    "            \n",
    "    torch.save(net.state_dict(), './results/model_{0}.pth'.format(name))\n",
    "    torch.save(optim.state_dict(), './results/optimizer_{0}.pth'.format(name))\n",
    "            \n",
    "    test()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    \n",
    "    return {\"train_losses\": train_losses, \"train_counter\": train_counter, \"test_losses\" : test_losses, \"test_accuracy\" : test_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_net = FullyConnected(n_hidden=3, input_size=(32*32*3), hidden_size=1024, output_size=10, grad_type='backprop')\n",
    "bp_data = test_train(bp_net, trainloader, testloader, name=\"backprop\")\n",
    "torch.save(bp_data, results_folder+'/bp_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_net = FullyConnected(n_hidden=3, input_size=(32*32*3), hidden_size=1024, output_size=10, grad_type='pseudo')\n",
    "ps_data = test_train(ps_net, trainloader, testloader, name=\"pseudo\")\n",
    "torch.save(ps_data, results_folder+'/ps_data.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_net = FullyConnected(n_hidden=3, input_size=(32*32*3), hidden_size=1024, output_size=10, grad_type='random')\n",
    "rd_data = test_train(rd_net, trainloader, testloader, name=\"random\")\n",
    "torch.save(rd_data, results_folder+'/rd_data.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu-only",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
